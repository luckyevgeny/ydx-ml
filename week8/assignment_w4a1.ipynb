{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 4 (Week 8). Assignment 1.\n",
    "\n",
    "Загрузите датасет digits с помощью функции load_digits из sklearn.datasets и подготовьте матрицу признаков X и ответы на обучающей выборке y (вам потребуются поля data и target в объекте, который возвращает load_digits).\n",
    "\n",
    "\n",
    "Для оценки качества далее нужно будет использовать cross_val_score из sklearn.cross_validation с параметром cv=10. Эта функция реализует k-fold cross validation c k равным значению параметра cv. Мы предлагаем использовать k=10, чтобы полученные оценки качества имели небольшой разброс, и было проще проверить полученные ответы. На практике же часто хватает и k=5. Функция cross_val_score будет возвращать numpy.ndarray, в котором будет k чисел - качество в каждом из k экспериментов k-fold cross validation. Для получения среднего значения (которое и будет оценкой качества работы) вызовите метод .mean() у массива, который возвращает cross_val_score.\n",
    "\n",
    "\n",
    "С небольшой вероятностью вы можете натолкнуться на случай, когда полученное вами качество в каком-то из пунктов не попадет в диапазон, заданный для правильных ответов - в этом случае попробуйте перезапустить ячейку с cross_val_score несколько раз и выбрать наиболее «типичное» значение. Если это не помогает, то где-то была допущена ошибка.\n",
    "\n",
    "\n",
    "Если вам захочется ускорить вычисление cross_val_score - можете попробовать использовать параметр n_jobs, но будьте осторожны: в одной из старых версий sklearn была ошибка, которая приводила к неверному результату работы cross_val_score при задании n_jobs отличным от 1. Сейчас такой проблемы возникнуть не должно, но проверить, что все в порядке, не будет лишним."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn import tree, cross_validation, ensemble\n",
    "\n",
    "\n",
    "def save_file(file_name, data):\n",
    "    with open(file_name, 'wt') as f:\n",
    "        f.write(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "\n",
    "1. Создайте DecisionTreeClassifier с настройками по умолчанию и измерьте *качество его работы* с помощью cross_val_score. Эта величина и будет *ответом в пункте 1*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110518a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPcAAAD7CAYAAAC2TgIoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTMuBpAg3kBThBpIi3EBShBtI6r86MxYZKbAIsgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110518ad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "digits = load_digits()\n",
    "\n",
    "plt.gray()\n",
    "plt.matshow(digits.images[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for K-Fold(10) = [ 0.80540541  0.85245902  0.85082873  0.80555556  0.77653631  0.90502793\n",
      "  0.86592179  0.8258427   0.84180791  0.83522727]\n",
      "Mean score =  0.836461261912\n"
     ]
    }
   ],
   "source": [
    "decision_tree_classifier = tree.DecisionTreeClassifier()\n",
    "\n",
    "scores = cross_validation.cross_val_score(\n",
    "    decision_tree_classifier,\n",
    "    digits.data, digits.target, cv=10)\n",
    "mean_score = scores.mean()\n",
    "\n",
    "print u'Scores for K-Fold(10) =', scores\n",
    "print u'Mean score = ', mean_score\n",
    "\n",
    "save_file('w4_a1_t1.txt', str(mean_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "\n",
    "2. Воспользуйтесь BaggingClassifier из sklearn.ensemble, чтобы обучить бэггинг над DecisionTreeClassifier. Используйте в BaggingClassifier параметры по умолчанию, задав только количество деревьев равным 100. *Качество классификации новой модели - ответ в пункте 2*. Обратите внимание, как соотносится качество работы композиции решающих деревьев с качеством работы одного решающего дерева."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for K-Fold(10) = [ 0.88108108  0.95628415  0.91160221  0.93333333  0.92178771  1.\n",
      "  0.96648045  0.91573034  0.87570621  0.9375    ]\n",
      "Mean score = 0.929950548556\n"
     ]
    }
   ],
   "source": [
    "bagging_classifier = ensemble.BaggingClassifier(\n",
    "    decision_tree_classifier,\n",
    "    n_estimators=100)\n",
    "\n",
    "scores = cross_validation.cross_val_score(\n",
    "    bagging_classifier,\n",
    "    digits.data, digits.target, cv=10)\n",
    "mean_score = scores.mean()\n",
    "\n",
    "print u'Scores for K-Fold(10) =', scores\n",
    "print u'Mean score =', mean_score\n",
    "\n",
    "save_file('w4_a1_t2.txt', str(mean_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "\n",
    "3. Теперь изучите параметры BaggingClassifier и выберите их такими, чтобы каждый базовый алгоритм обучался не на всех d признаках, а на $\\sqrt(d)$ случайных признаков. *Качество* работы получившегося классификатора - ответ в пункте 3. Корень из числа признаков - часто используемая эвристика в задачах классификации, в задачах регрессии же часто берут число признаков, деленное на три. Но в общем случае ничто не мешает вам выбирать любое другое число случайных признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for K-Fold(10) = [ 0.89189189  0.94535519  0.93370166  0.9         0.9273743   0.94972067\n",
      "  0.96089385  0.98314607  0.88700565  0.91477273]\n",
      "Mean score = 0.929386201183\n"
     ]
    }
   ],
   "source": [
    "bagging_classifier2 = ensemble.BaggingClassifier(\n",
    "    decision_tree_classifier,\n",
    "    n_estimators=100,\n",
    "    max_features=int(np.sqrt(digits.data.shape[1])))\n",
    "\n",
    "scores = cross_validation.cross_val_score(\n",
    "    bagging_classifier2,\n",
    "    digits.data, digits.target, cv=10)\n",
    "mean_score = scores.mean()\n",
    "\n",
    "print u'Scores for K-Fold(10) =', scores\n",
    "print u'Mean score =', mean_score\n",
    "\n",
    "save_file('w4_a1_t3.txt', str(mean_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4\n",
    "\n",
    "4. Наконец, давайте попробуем выбирать случайные признаки не один раз на все дерево, а при построении каждой вершины дерева. Сделать это несложно: нужно убрать выбор случайного подмножества признаков в BaggingClassifier и добавить его в DecisionTreeClassifier. Какой параметр за это отвечает, можно понять из документации sklearn, либо просто попробовать угадать (скорее всего, у вас сразу получится). Попробуйте выбирать опять же $\\sqrt{d}$ признаков. Качество полученного классификатора на контрольной выборке и будет ответом в пункте 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for K-Fold(10) = [ 0.9027027   0.96721311  0.93922652  0.97222222  0.95530726  0.97206704\n",
      "  0.97206704  0.96629213  0.92655367  0.94886364]\n",
      "Mean score = 0.952251534331\n"
     ]
    }
   ],
   "source": [
    "decision_tree_classifier2 = tree.DecisionTreeClassifier(max_features='sqrt')\n",
    "\n",
    "bagging_classifier3 = ensemble.BaggingClassifier(\n",
    "    decision_tree_classifier2,\n",
    "    n_estimators=100)\n",
    "\n",
    "scores = cross_validation.cross_val_score(\n",
    "    bagging_classifier3,\n",
    "    digits.data, digits.target, cv=10)\n",
    "mean_score = scores.mean()\n",
    "\n",
    "print u'Scores for K-Fold(10) =', scores\n",
    "print u'Mean score =', mean_score\n",
    "\n",
    "save_file('w4_a1_t4.txt', str(mean_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5\n",
    "\n",
    "5. Полученный в пункте 4 классификатор - бэггинг на рандомизированных деревьях (в которых при построении каждой вершины выбирается случайное подмножество признаков и разбиение ищется только по ним). Это в точности соответствует алгоритму Random Forest, поэтому почему бы не сравнить качество работы классификатора с RandomForestClassifier из sklearn.ensemble. Сделайте это, а затем изучите, как качество классификации на данном датасете зависит от количества деревьев, количества признаков, выбираемых при построении каждой вершины дерева, а также ограничений на глубину дерева. Для наглядности лучше построить графики зависимости качества от значений параметров, но для сдачи задания это делать не обязательно. На основе наблюдений *выпишите через пробел номера правильных утверждений* из приведенных ниже в порядке возрастания номера (это будет ответ в п.5)\n",
    "\n",
    "\n",
    "* 1) Случайный лес сильно переобучается с ростом количества деревьев\n",
    "* 2) При очень маленьком числе деревьев (5, 10, 15), случайный лес работает хуже, чем при большем числе деревьев\n",
    "* 3) С ростом количества деревьев в случайном лесе, в какой-то момент деревьев становится достаточно для высокого качества классификации, а затем качество существенно не меняется.\n",
    "* 4) При большом количестве признаков (для данного датасета - 40, 50) качество классификации становится хуже, чем при малом количестве признаков (5, 10). Это связано с тем, что чем меньше признаков выбирается в каждом узле, тем более различными получаются деревья (ведь деревья сильно неустойчивы к изменениям в обучающей выборке), и тем лучше работает их композиция.\n",
    "* 5) При большом количестве признаков (40, 50, 60) качество классификации лучше, чем при малом количестве признаков (5, 10). Это связано с тем, что чем больше признаков - тем больше информации об объектах, а значит алгоритм может делать прогнозы более точно.\n",
    "* 6) При небольшой максимальной глубине деревьев (5-6) качество работы случайного леса намного лучше, чем без ограничения глубины, т.к. деревья получаются не переобученными. С ростом глубины деревьев качество ухудшается.\n",
    "* 7) При небольшой максимальной глубине деревьев (5-6) качество работы случайного леса заметно хуже, чем без ограничений, т.к. деревья получаются недообученными. С ростом глубины качество сначала улучшается, а затем не меняется существенно, т.к. из-за усреднения прогнозов и различий деревьев их переобученность в бэггинге не сказывается на итоговом качестве (все деревья преобучены по-разному, и при усреднении они компенсируют переобученность друг-друга)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for K-Fold(10) = [ 0.9027027   0.97814208  0.94475138  0.94444444  0.96089385  0.97206704\n",
      "  0.97765363  0.97752809  0.95480226  0.94886364]\n",
      "Mean score = 0.956184911614\n"
     ]
    }
   ],
   "source": [
    "random_forest = ensemble.RandomForestClassifier(n_estimators=100, max_features='sqrt')\n",
    "\n",
    "scores = cross_validation.cross_val_score(\n",
    "    random_forest,\n",
    "    digits.data, digits.target, cv=10)\n",
    "\n",
    "print u'Scores for K-Fold(10) =', scores\n",
    "print u'Mean score =', scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ответ: 2,3,4,7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_file('w4_a1_t5.txt', '2 3 4 7')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
